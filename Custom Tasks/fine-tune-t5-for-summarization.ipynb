{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import cuda\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Inshorts Cleaned Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "      <th>Source</th>\n",
       "      <th>Time</th>\n",
       "      <th>Publish Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "      <td>The New Indian Express</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>2017-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>22:18:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "      <td>Hindustan Times</td>\n",
       "      <td>23:39:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>23:08:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>23:24:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short                 Source   \\\n",
       "0  The CBI on Saturday booked four former officia...  The New Indian Express   \n",
       "1  Chief Justice JS Khehar has said the Supreme C...                 Outlook   \n",
       "2  At least three people were killed, including a...         Hindustan Times   \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...                Livemint   \n",
       "4  TV news anchor Arnab Goswami has said he was t...                 YouTube   \n",
       "\n",
       "      Time  Publish Date  \n",
       "0  09:25:00   2017-03-26  \n",
       "1  22:18:00   2017-03-25  \n",
       "2  23:39:00   2017-03-25  \n",
       "3  23:08:00   2017-03-25  \n",
       "4  23:24:00   2017-03-25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.Headline\n",
    "        self.ctext = self.data.Short\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length = self.source_len, padding = 'max_length',\\\n",
    "                                                  return_tensors = 'pt')\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length = self.summ_len, padding = 'max_length',\\\n",
    "                                                  return_tensors = 'pt')\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype = torch.long), \n",
    "            'source_mask': source_mask.to(dtype = torch.long), \n",
    "            'target_ids': target_ids.to(dtype = torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype = torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous() # make y_ids contiguous \n",
    "        lm_labels = y[:, 1:].clone().detach() # make fast copy\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100 # replace pad tokens \n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids = y_ids, labels = lm_labels)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        if _%500==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length = 100, \n",
    "                num_beams = 2,\n",
    "                repetition_penalty = 2.5, \n",
    "                length_penalty = 1.0, \n",
    "                early_stopping = True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                     for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                      for t in y]\n",
    "            if _%100==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (55104, 2)\n",
      "TRAIN Dataset: (44083, 2)\n",
      "TEST Dataset: (11021, 2)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 2 \n",
    "TRAIN_EPOCHS = 10      \n",
    "VAL_EPOCHS = 1 \n",
    "LEARNING_RATE = 1e-4    \n",
    "SEED = 42               \n",
    "MAX_LEN = 512\n",
    "SUMMARY_LEN = 100\n",
    "\n",
    "torch.manual_seed(SEED) \n",
    "np.random.seed(SEED) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "df = df[['Headline','Short']]\n",
    "df.Headline = 'summarize: ' + df.Headline\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = df.sample(frac=train_size,random_state = SEED)\n",
    "val_dataset = df.drop(train_dataset.index).reset_index(drop = True)\n",
    "train_dataset = train_dataset.reset_index(drop = True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
    "val_set = CustomDataset(val_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': TRAIN_BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': VALID_BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Fine-Tuning for the model on our dataset\n",
      "Epoch: 0, Loss:  7.785033226013184\n",
      "Epoch: 0, Loss:  4.137582302093506\n",
      "Epoch: 0, Loss:  1.672741413116455\n",
      "Epoch: 0, Loss:  1.0173431634902954\n",
      "Epoch: 0, Loss:  1.4495106935501099\n",
      "Epoch: 0, Loss:  1.2304035425186157\n",
      "Epoch: 0, Loss:  1.1589051485061646\n",
      "Epoch: 0, Loss:  1.6307483911514282\n",
      "Epoch: 0, Loss:  2.211906909942627\n",
      "Epoch: 0, Loss:  1.33210027217865\n",
      "Epoch: 0, Loss:  0.6856052875518799\n",
      "Epoch: 0, Loss:  2.68495774269104\n",
      "Epoch: 0, Loss:  0.8948730826377869\n",
      "Epoch: 0, Loss:  0.6205958127975464\n",
      "Epoch: 0, Loss:  2.5478999614715576\n",
      "Epoch: 0, Loss:  1.117437481880188\n",
      "Epoch: 0, Loss:  0.7587160468101501\n",
      "Epoch: 0, Loss:  0.6147298216819763\n",
      "Epoch: 0, Loss:  1.9005123376846313\n",
      "Epoch: 0, Loss:  0.5888300538063049\n",
      "Epoch: 0, Loss:  1.3362209796905518\n",
      "Epoch: 0, Loss:  1.0849220752716064\n",
      "Epoch: 0, Loss:  1.4622905254364014\n",
      "Epoch: 0, Loss:  0.7670914530754089\n",
      "Epoch: 0, Loss:  0.5742753744125366\n",
      "Epoch: 0, Loss:  1.5851795673370361\n",
      "Epoch: 0, Loss:  2.5978469848632812\n",
      "Epoch: 0, Loss:  1.3461744785308838\n",
      "Epoch: 0, Loss:  0.8412933349609375\n",
      "Epoch: 0, Loss:  0.14351747930049896\n",
      "Epoch: 0, Loss:  0.3512742519378662\n",
      "Epoch: 0, Loss:  1.801042914390564\n",
      "Epoch: 0, Loss:  0.49638333916664124\n",
      "Epoch: 0, Loss:  1.3547321557998657\n",
      "Epoch: 0, Loss:  0.7509430050849915\n",
      "Epoch: 0, Loss:  1.7133039236068726\n",
      "Epoch: 0, Loss:  0.8110716938972473\n",
      "Epoch: 0, Loss:  2.0885214805603027\n",
      "Epoch: 0, Loss:  1.091427206993103\n",
      "Epoch: 0, Loss:  0.7648110389709473\n",
      "Epoch: 0, Loss:  0.526159405708313\n",
      "Epoch: 0, Loss:  0.6779009699821472\n",
      "Epoch: 0, Loss:  0.5735129117965698\n",
      "Epoch: 0, Loss:  0.6339665055274963\n",
      "Epoch: 0, Loss:  1.0028711557388306\n",
      "Epoch: 1, Loss:  0.9001802206039429\n",
      "Epoch: 1, Loss:  1.6236406564712524\n",
      "Epoch: 1, Loss:  0.5660325884819031\n",
      "Epoch: 1, Loss:  0.739277720451355\n",
      "Epoch: 1, Loss:  0.8893336653709412\n",
      "Epoch: 1, Loss:  0.3907378613948822\n",
      "Epoch: 1, Loss:  1.9096593856811523\n",
      "Epoch: 1, Loss:  1.1366045475006104\n",
      "Epoch: 1, Loss:  0.7470844984054565\n",
      "Epoch: 1, Loss:  1.0600653886795044\n",
      "Epoch: 1, Loss:  1.3958200216293335\n",
      "Epoch: 1, Loss:  0.5483042001724243\n",
      "Epoch: 1, Loss:  1.0963866710662842\n",
      "Epoch: 1, Loss:  1.1549831628799438\n",
      "Epoch: 1, Loss:  1.229383111000061\n",
      "Epoch: 1, Loss:  1.6417523622512817\n",
      "Epoch: 1, Loss:  1.6303776502609253\n",
      "Epoch: 1, Loss:  0.5401489734649658\n",
      "Epoch: 1, Loss:  1.041902780532837\n",
      "Epoch: 1, Loss:  1.288449764251709\n",
      "Epoch: 1, Loss:  1.2367552518844604\n",
      "Epoch: 1, Loss:  2.0267391204833984\n",
      "Epoch: 1, Loss:  1.253031849861145\n",
      "Epoch: 1, Loss:  0.6292364001274109\n",
      "Epoch: 1, Loss:  0.7608362436294556\n",
      "Epoch: 1, Loss:  0.44040003418922424\n",
      "Epoch: 1, Loss:  0.4595086872577667\n",
      "Epoch: 1, Loss:  1.5921568870544434\n",
      "Epoch: 1, Loss:  0.9127006530761719\n",
      "Epoch: 1, Loss:  1.5531474351882935\n",
      "Epoch: 1, Loss:  1.019667387008667\n",
      "Epoch: 1, Loss:  0.6305238604545593\n",
      "Epoch: 1, Loss:  0.3209304213523865\n",
      "Epoch: 1, Loss:  1.1500718593597412\n",
      "Epoch: 1, Loss:  0.5616679191589355\n",
      "Epoch: 1, Loss:  0.8334326148033142\n",
      "Epoch: 1, Loss:  1.5711923837661743\n",
      "Epoch: 1, Loss:  0.4144880771636963\n",
      "Epoch: 1, Loss:  1.0500258207321167\n",
      "Epoch: 1, Loss:  0.4777812957763672\n",
      "Epoch: 1, Loss:  1.3995184898376465\n",
      "Epoch: 1, Loss:  0.5146478414535522\n",
      "Epoch: 1, Loss:  0.8951826691627502\n",
      "Epoch: 1, Loss:  1.717141032218933\n",
      "Epoch: 1, Loss:  0.8825222253799438\n",
      "Epoch: 2, Loss:  0.9759440422058105\n",
      "Epoch: 2, Loss:  0.9530680775642395\n",
      "Epoch: 2, Loss:  1.1555522680282593\n",
      "Epoch: 2, Loss:  0.9496732354164124\n",
      "Epoch: 2, Loss:  0.9520404934883118\n",
      "Epoch: 2, Loss:  0.5017721056938171\n",
      "Epoch: 2, Loss:  0.693750262260437\n",
      "Epoch: 2, Loss:  0.46497827768325806\n",
      "Epoch: 2, Loss:  0.29031074047088623\n",
      "Epoch: 2, Loss:  0.8824865221977234\n",
      "Epoch: 2, Loss:  0.30166611075401306\n",
      "Epoch: 2, Loss:  0.97735196352005\n",
      "Epoch: 2, Loss:  0.7510808706283569\n",
      "Epoch: 2, Loss:  2.139770269393921\n",
      "Epoch: 2, Loss:  0.17076422274112701\n",
      "Epoch: 2, Loss:  0.8030434846878052\n",
      "Epoch: 2, Loss:  0.9311141967773438\n",
      "Epoch: 2, Loss:  1.3282654285430908\n",
      "Epoch: 2, Loss:  1.4061428308486938\n",
      "Epoch: 2, Loss:  0.8658605813980103\n",
      "Epoch: 2, Loss:  1.0332452058792114\n",
      "Epoch: 2, Loss:  0.3963586986064911\n",
      "Epoch: 2, Loss:  1.025189757347107\n",
      "Epoch: 2, Loss:  0.8685488700866699\n",
      "Epoch: 2, Loss:  1.1586099863052368\n",
      "Epoch: 2, Loss:  0.6801493167877197\n",
      "Epoch: 2, Loss:  0.3986618220806122\n",
      "Epoch: 2, Loss:  0.5462196469306946\n",
      "Epoch: 2, Loss:  2.0915868282318115\n",
      "Epoch: 2, Loss:  0.7255107760429382\n",
      "Epoch: 2, Loss:  0.8460035920143127\n",
      "Epoch: 2, Loss:  1.0396937131881714\n",
      "Epoch: 2, Loss:  1.0676981210708618\n",
      "Epoch: 2, Loss:  1.3561345338821411\n",
      "Epoch: 2, Loss:  0.41746577620506287\n",
      "Epoch: 2, Loss:  0.6298661828041077\n",
      "Epoch: 2, Loss:  0.7480572462081909\n",
      "Epoch: 2, Loss:  0.5582373738288879\n",
      "Epoch: 2, Loss:  0.5703322887420654\n",
      "Epoch: 2, Loss:  0.8357671499252319\n",
      "Epoch: 2, Loss:  1.0043432712554932\n",
      "Epoch: 2, Loss:  1.0403556823730469\n",
      "Epoch: 2, Loss:  0.9149281978607178\n",
      "Epoch: 2, Loss:  0.21906040608882904\n",
      "Epoch: 2, Loss:  0.9592910408973694\n",
      "Epoch: 3, Loss:  0.2553691565990448\n",
      "Epoch: 3, Loss:  0.7965829968452454\n",
      "Epoch: 3, Loss:  1.343369483947754\n",
      "Epoch: 3, Loss:  0.6329855918884277\n",
      "Epoch: 3, Loss:  0.7638391256332397\n",
      "Epoch: 3, Loss:  0.33143970370292664\n",
      "Epoch: 3, Loss:  0.43517813086509705\n",
      "Epoch: 3, Loss:  0.6234505772590637\n",
      "Epoch: 3, Loss:  0.2504962682723999\n",
      "Epoch: 3, Loss:  0.4596906006336212\n",
      "Epoch: 3, Loss:  0.8285715579986572\n",
      "Epoch: 3, Loss:  0.6335236430168152\n",
      "Epoch: 3, Loss:  1.2385681867599487\n",
      "Epoch: 3, Loss:  0.9573354721069336\n",
      "Epoch: 3, Loss:  0.4243936836719513\n",
      "Epoch: 3, Loss:  0.7308568954467773\n",
      "Epoch: 3, Loss:  0.15571793913841248\n",
      "Epoch: 3, Loss:  0.39221128821372986\n",
      "Epoch: 3, Loss:  0.8733384609222412\n",
      "Epoch: 3, Loss:  0.7796003222465515\n",
      "Epoch: 3, Loss:  0.7377915382385254\n",
      "Epoch: 3, Loss:  0.5096737146377563\n",
      "Epoch: 3, Loss:  0.3862815797328949\n",
      "Epoch: 3, Loss:  0.43734467029571533\n",
      "Epoch: 3, Loss:  0.6547001004219055\n",
      "Epoch: 3, Loss:  0.4632859230041504\n",
      "Epoch: 3, Loss:  0.5573891997337341\n",
      "Epoch: 3, Loss:  0.8233839273452759\n",
      "Epoch: 3, Loss:  0.5138787627220154\n",
      "Epoch: 3, Loss:  0.5633965730667114\n",
      "Epoch: 3, Loss:  0.6151410341262817\n",
      "Epoch: 3, Loss:  0.6137111186981201\n",
      "Epoch: 3, Loss:  0.2897009551525116\n",
      "Epoch: 3, Loss:  0.5885123610496521\n",
      "Epoch: 3, Loss:  0.4764850437641144\n",
      "Epoch: 3, Loss:  0.1731717884540558\n",
      "Epoch: 3, Loss:  1.0612634420394897\n",
      "Epoch: 3, Loss:  0.3503178656101227\n",
      "Epoch: 3, Loss:  1.4109606742858887\n",
      "Epoch: 3, Loss:  0.7055050134658813\n",
      "Epoch: 3, Loss:  0.4188506305217743\n",
      "Epoch: 3, Loss:  1.6381042003631592\n",
      "Epoch: 3, Loss:  0.7418708205223083\n",
      "Epoch: 3, Loss:  0.751773476600647\n",
      "Epoch: 3, Loss:  0.1681186407804489\n",
      "Epoch: 4, Loss:  0.8210211396217346\n",
      "Epoch: 4, Loss:  0.14122100174427032\n",
      "Epoch: 4, Loss:  0.6748090386390686\n",
      "Epoch: 4, Loss:  1.2139277458190918\n",
      "Epoch: 4, Loss:  0.4659411907196045\n",
      "Epoch: 4, Loss:  0.8866797089576721\n",
      "Epoch: 4, Loss:  0.22684863209724426\n",
      "Epoch: 4, Loss:  0.6820808053016663\n",
      "Epoch: 4, Loss:  0.7631335854530334\n",
      "Epoch: 4, Loss:  0.5785103440284729\n",
      "Epoch: 4, Loss:  0.585341215133667\n",
      "Epoch: 4, Loss:  0.48434779047966003\n",
      "Epoch: 4, Loss:  1.0255147218704224\n",
      "Epoch: 4, Loss:  0.7054988741874695\n",
      "Epoch: 4, Loss:  0.33452385663986206\n",
      "Epoch: 4, Loss:  0.7000234127044678\n",
      "Epoch: 4, Loss:  0.6744033098220825\n",
      "Epoch: 4, Loss:  0.22952111065387726\n",
      "Epoch: 4, Loss:  0.3623356223106384\n",
      "Epoch: 4, Loss:  0.6190685033798218\n",
      "Epoch: 4, Loss:  1.4659382104873657\n",
      "Epoch: 4, Loss:  1.124860167503357\n",
      "Epoch: 4, Loss:  0.6059677004814148\n",
      "Epoch: 4, Loss:  0.34069669246673584\n",
      "Epoch: 4, Loss:  0.6877173781394958\n",
      "Epoch: 4, Loss:  0.1275986284017563\n",
      "Epoch: 4, Loss:  0.2690259516239166\n",
      "Epoch: 4, Loss:  0.6914183497428894\n",
      "Epoch: 4, Loss:  0.4785413146018982\n",
      "Epoch: 4, Loss:  0.7094259858131409\n",
      "Epoch: 4, Loss:  0.5006459951400757\n",
      "Epoch: 4, Loss:  0.29281631112098694\n",
      "Epoch: 4, Loss:  0.37999841570854187\n",
      "Epoch: 4, Loss:  0.42333558201789856\n",
      "Epoch: 4, Loss:  0.45994266867637634\n",
      "Epoch: 4, Loss:  0.4506843686103821\n",
      "Epoch: 4, Loss:  0.33183613419532776\n",
      "Epoch: 4, Loss:  0.35657960176467896\n",
      "Epoch: 4, Loss:  0.4889771640300751\n",
      "Epoch: 4, Loss:  1.1560168266296387\n",
      "Epoch: 4, Loss:  0.5623343586921692\n",
      "Epoch: 4, Loss:  0.24668768048286438\n",
      "Epoch: 4, Loss:  0.6994596719741821\n",
      "Epoch: 4, Loss:  0.6663894653320312\n",
      "Epoch: 4, Loss:  0.4109489619731903\n",
      "Epoch: 5, Loss:  0.5197930335998535\n",
      "Epoch: 5, Loss:  0.29689821600914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.5479031205177307\n",
      "Epoch: 5, Loss:  0.6824887990951538\n",
      "Epoch: 5, Loss:  0.7926934957504272\n",
      "Epoch: 5, Loss:  0.6344553828239441\n",
      "Epoch: 5, Loss:  0.585287868976593\n",
      "Epoch: 5, Loss:  0.43453362584114075\n",
      "Epoch: 5, Loss:  0.21496695280075073\n",
      "Epoch: 5, Loss:  0.54149329662323\n",
      "Epoch: 5, Loss:  0.2942473292350769\n",
      "Epoch: 5, Loss:  0.1154533326625824\n",
      "Epoch: 5, Loss:  0.5167763829231262\n",
      "Epoch: 5, Loss:  0.47101831436157227\n",
      "Epoch: 5, Loss:  0.25115248560905457\n",
      "Epoch: 5, Loss:  0.39807558059692383\n",
      "Epoch: 5, Loss:  0.4964490532875061\n",
      "Epoch: 5, Loss:  0.5140594244003296\n",
      "Epoch: 5, Loss:  1.093062162399292\n",
      "Epoch: 5, Loss:  0.48008447885513306\n",
      "Epoch: 5, Loss:  0.672563374042511\n",
      "Epoch: 5, Loss:  0.3136318325996399\n",
      "Epoch: 5, Loss:  0.7942981123924255\n",
      "Epoch: 5, Loss:  0.5144006609916687\n",
      "Epoch: 5, Loss:  0.34185707569122314\n",
      "Epoch: 5, Loss:  1.0470203161239624\n",
      "Epoch: 5, Loss:  0.2874961495399475\n",
      "Epoch: 5, Loss:  0.5579469203948975\n",
      "Epoch: 5, Loss:  0.08542859554290771\n",
      "Epoch: 5, Loss:  0.4777476489543915\n",
      "Epoch: 5, Loss:  0.5886339545249939\n",
      "Epoch: 5, Loss:  0.6613656878471375\n",
      "Epoch: 5, Loss:  0.3579002618789673\n",
      "Epoch: 5, Loss:  0.5981273651123047\n",
      "Epoch: 5, Loss:  0.43051305413246155\n",
      "Epoch: 5, Loss:  0.6374301314353943\n",
      "Epoch: 5, Loss:  0.2695639133453369\n",
      "Epoch: 5, Loss:  0.28503626585006714\n",
      "Epoch: 5, Loss:  0.38138774037361145\n",
      "Epoch: 5, Loss:  0.7697534561157227\n",
      "Epoch: 5, Loss:  0.5318300724029541\n",
      "Epoch: 5, Loss:  0.5058669447898865\n",
      "Epoch: 5, Loss:  0.687707781791687\n",
      "Epoch: 5, Loss:  0.3264484703540802\n",
      "Epoch: 5, Loss:  0.6355116963386536\n",
      "Epoch: 6, Loss:  0.36964133381843567\n",
      "Epoch: 6, Loss:  0.48656293749809265\n",
      "Epoch: 6, Loss:  0.5640959143638611\n",
      "Epoch: 6, Loss:  0.5513757467269897\n",
      "Epoch: 6, Loss:  0.19504430890083313\n",
      "Epoch: 6, Loss:  0.3151486814022064\n",
      "Epoch: 6, Loss:  0.7045778632164001\n",
      "Epoch: 6, Loss:  0.2528042793273926\n",
      "Epoch: 6, Loss:  0.40561243891716003\n",
      "Epoch: 6, Loss:  0.9032406210899353\n",
      "Epoch: 6, Loss:  0.26484018564224243\n",
      "Epoch: 6, Loss:  0.47739607095718384\n",
      "Epoch: 6, Loss:  0.5955206751823425\n",
      "Epoch: 6, Loss:  0.7755969166755676\n",
      "Epoch: 6, Loss:  0.3476923704147339\n",
      "Epoch: 6, Loss:  0.26407134532928467\n",
      "Epoch: 6, Loss:  0.39574477076530457\n",
      "Epoch: 6, Loss:  0.7217389941215515\n",
      "Epoch: 6, Loss:  0.2358129322528839\n",
      "Epoch: 6, Loss:  0.25935301184654236\n",
      "Epoch: 6, Loss:  0.5638282299041748\n",
      "Epoch: 6, Loss:  0.5693399906158447\n",
      "Epoch: 6, Loss:  0.670199990272522\n",
      "Epoch: 6, Loss:  0.3113551437854767\n",
      "Epoch: 6, Loss:  0.11407279968261719\n",
      "Epoch: 6, Loss:  0.34554776549339294\n",
      "Epoch: 6, Loss:  0.15853038430213928\n",
      "Epoch: 6, Loss:  0.25394076108932495\n",
      "Epoch: 6, Loss:  0.3548656404018402\n",
      "Epoch: 6, Loss:  0.3481385111808777\n",
      "Epoch: 6, Loss:  0.2648516595363617\n",
      "Epoch: 6, Loss:  0.5317959785461426\n",
      "Epoch: 6, Loss:  0.5781586766242981\n",
      "Epoch: 6, Loss:  0.33880242705345154\n",
      "Epoch: 6, Loss:  0.5035247206687927\n",
      "Epoch: 6, Loss:  0.9946308135986328\n",
      "Epoch: 6, Loss:  0.41598862409591675\n",
      "Epoch: 6, Loss:  0.5473434925079346\n",
      "Epoch: 6, Loss:  0.5672476291656494\n",
      "Epoch: 6, Loss:  0.9979732036590576\n",
      "Epoch: 6, Loss:  0.7298692464828491\n",
      "Epoch: 6, Loss:  0.3172464072704315\n",
      "Epoch: 6, Loss:  0.27111193537712097\n",
      "Epoch: 6, Loss:  0.5294090509414673\n",
      "Epoch: 6, Loss:  0.5982139110565186\n",
      "Epoch: 7, Loss:  0.6046637296676636\n",
      "Epoch: 7, Loss:  0.39336568117141724\n",
      "Epoch: 7, Loss:  0.16638030111789703\n",
      "Epoch: 7, Loss:  0.3324985206127167\n",
      "Epoch: 7, Loss:  0.2550407946109772\n",
      "Epoch: 7, Loss:  0.24957960844039917\n",
      "Epoch: 7, Loss:  0.13588598370552063\n",
      "Epoch: 7, Loss:  0.14268717169761658\n",
      "Epoch: 7, Loss:  0.4195917844772339\n",
      "Epoch: 7, Loss:  0.3277493715286255\n",
      "Epoch: 7, Loss:  0.4523962438106537\n",
      "Epoch: 7, Loss:  0.46752965450286865\n",
      "Epoch: 7, Loss:  0.28329968452453613\n",
      "Epoch: 7, Loss:  0.3511104881763458\n",
      "Epoch: 7, Loss:  0.26100847125053406\n",
      "Epoch: 7, Loss:  0.20341263711452484\n",
      "Epoch: 7, Loss:  0.4428741931915283\n",
      "Epoch: 7, Loss:  0.21250326931476593\n",
      "Epoch: 7, Loss:  0.21496620774269104\n",
      "Epoch: 7, Loss:  0.7355879545211792\n",
      "Epoch: 7, Loss:  0.40183117985725403\n",
      "Epoch: 7, Loss:  0.5919803977012634\n",
      "Epoch: 7, Loss:  0.3818311393260956\n",
      "Epoch: 7, Loss:  0.5103511214256287\n",
      "Epoch: 7, Loss:  0.32111886143684387\n",
      "Epoch: 7, Loss:  0.2265806347131729\n",
      "Epoch: 7, Loss:  0.25164368748664856\n",
      "Epoch: 7, Loss:  0.7713194489479065\n",
      "Epoch: 7, Loss:  0.08208439499139786\n",
      "Epoch: 7, Loss:  0.11426090449094772\n",
      "Epoch: 7, Loss:  0.4091567099094391\n",
      "Epoch: 7, Loss:  0.028225945308804512\n",
      "Epoch: 7, Loss:  0.9931460022926331\n",
      "Epoch: 7, Loss:  0.44778764247894287\n",
      "Epoch: 7, Loss:  0.10529983043670654\n",
      "Epoch: 7, Loss:  0.2510199248790741\n",
      "Epoch: 7, Loss:  0.3664848804473877\n",
      "Epoch: 7, Loss:  0.47718730568885803\n",
      "Epoch: 7, Loss:  0.2459748536348343\n",
      "Epoch: 7, Loss:  0.1338130682706833\n",
      "Epoch: 7, Loss:  0.26646655797958374\n",
      "Epoch: 7, Loss:  0.1938677728176117\n",
      "Epoch: 7, Loss:  0.19766008853912354\n",
      "Epoch: 7, Loss:  0.29312068223953247\n",
      "Epoch: 7, Loss:  0.09985174983739853\n",
      "Epoch: 8, Loss:  0.18273085355758667\n",
      "Epoch: 8, Loss:  0.08978253602981567\n",
      "Epoch: 8, Loss:  0.21091410517692566\n",
      "Epoch: 8, Loss:  0.07202686369419098\n",
      "Epoch: 8, Loss:  0.19039468467235565\n",
      "Epoch: 8, Loss:  0.26335152983665466\n",
      "Epoch: 8, Loss:  0.20564720034599304\n",
      "Epoch: 8, Loss:  0.25261861085891724\n",
      "Epoch: 8, Loss:  0.12895812094211578\n",
      "Epoch: 8, Loss:  0.17671622335910797\n",
      "Epoch: 8, Loss:  0.17374908924102783\n",
      "Epoch: 8, Loss:  0.06740661710500717\n",
      "Epoch: 8, Loss:  0.4465215802192688\n",
      "Epoch: 8, Loss:  0.441182404756546\n",
      "Epoch: 8, Loss:  0.24758583307266235\n",
      "Epoch: 8, Loss:  0.5328820943832397\n",
      "Epoch: 8, Loss:  0.2919142246246338\n",
      "Epoch: 8, Loss:  0.33620569109916687\n",
      "Epoch: 8, Loss:  0.5434709191322327\n",
      "Epoch: 8, Loss:  0.5499898195266724\n",
      "Epoch: 8, Loss:  0.4159926176071167\n",
      "Epoch: 8, Loss:  0.49439239501953125\n",
      "Epoch: 8, Loss:  0.12291958183050156\n",
      "Epoch: 8, Loss:  0.1267223358154297\n",
      "Epoch: 8, Loss:  0.2870910167694092\n",
      "Epoch: 8, Loss:  0.061403293162584305\n",
      "Epoch: 8, Loss:  0.5296607613563538\n",
      "Epoch: 8, Loss:  0.7155592441558838\n",
      "Epoch: 8, Loss:  0.08667148649692535\n",
      "Epoch: 8, Loss:  0.4515407383441925\n",
      "Epoch: 8, Loss:  0.3694080114364624\n",
      "Epoch: 8, Loss:  0.6009960770606995\n",
      "Epoch: 8, Loss:  0.2732628881931305\n",
      "Epoch: 8, Loss:  0.4534880518913269\n",
      "Epoch: 8, Loss:  0.12666435539722443\n",
      "Epoch: 8, Loss:  0.2645660936832428\n",
      "Epoch: 8, Loss:  0.201124370098114\n",
      "Epoch: 8, Loss:  0.11711054295301437\n",
      "Epoch: 8, Loss:  1.159468173980713\n",
      "Epoch: 8, Loss:  0.4546942114830017\n",
      "Epoch: 8, Loss:  0.29289141297340393\n",
      "Epoch: 8, Loss:  0.37707436084747314\n",
      "Epoch: 8, Loss:  0.1059417650103569\n",
      "Epoch: 8, Loss:  0.5888006687164307\n",
      "Epoch: 8, Loss:  0.0838908851146698\n",
      "Epoch: 9, Loss:  0.13315396010875702\n",
      "Epoch: 9, Loss:  0.4689267575740814\n",
      "Epoch: 9, Loss:  0.06435509026050568\n",
      "Epoch: 9, Loss:  0.5121047496795654\n",
      "Epoch: 9, Loss:  0.18272805213928223\n",
      "Epoch: 9, Loss:  0.7207533121109009\n",
      "Epoch: 9, Loss:  0.1609676033258438\n",
      "Epoch: 9, Loss:  0.3605039417743683\n",
      "Epoch: 9, Loss:  0.06019078195095062\n",
      "Epoch: 9, Loss:  0.3244018852710724\n",
      "Epoch: 9, Loss:  0.38961261510849\n",
      "Epoch: 9, Loss:  0.42596662044525146\n",
      "Epoch: 9, Loss:  0.3522399365901947\n",
      "Epoch: 9, Loss:  0.1773490011692047\n",
      "Epoch: 9, Loss:  0.26658958196640015\n",
      "Epoch: 9, Loss:  0.3215066194534302\n",
      "Epoch: 9, Loss:  0.1078452318906784\n",
      "Epoch: 9, Loss:  0.04018126055598259\n",
      "Epoch: 9, Loss:  0.21931733191013336\n",
      "Epoch: 9, Loss:  0.14724883437156677\n",
      "Epoch: 9, Loss:  0.13739456236362457\n",
      "Epoch: 9, Loss:  0.34985318779945374\n",
      "Epoch: 9, Loss:  0.1979278177022934\n",
      "Epoch: 9, Loss:  0.25916269421577454\n",
      "Epoch: 9, Loss:  0.09079615026712418\n",
      "Epoch: 9, Loss:  0.29760003089904785\n",
      "Epoch: 9, Loss:  0.24111489951610565\n",
      "Epoch: 9, Loss:  0.37685728073120117\n",
      "Epoch: 9, Loss:  0.4037986099720001\n",
      "Epoch: 9, Loss:  0.26324206590652466\n",
      "Epoch: 9, Loss:  0.7287737727165222\n",
      "Epoch: 9, Loss:  0.05251787602901459\n",
      "Epoch: 9, Loss:  0.7792083024978638\n",
      "Epoch: 9, Loss:  0.5218324661254883\n",
      "Epoch: 9, Loss:  0.12279875576496124\n",
      "Epoch: 9, Loss:  0.32119840383529663\n",
      "Epoch: 9, Loss:  0.4088400602340698\n",
      "Epoch: 9, Loss:  0.2418496310710907\n",
      "Epoch: 9, Loss:  0.19301153719425201\n",
      "Epoch: 9, Loss:  0.10301033407449722\n",
      "Epoch: 9, Loss:  0.6519781351089478\n",
      "Epoch: 9, Loss:  0.28604233264923096\n",
      "Epoch: 9, Loss:  0.3241215646266937\n",
      "Epoch: 9, Loss:  0.2206241637468338\n",
      "Epoch: 9, Loss:  0.3018771708011627\n"
     ]
    }
   ],
   "source": [
    "print('Initiating Fine-Tuning for the model on our dataset')\n",
    "\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    train(epoch, tokenizer, model, device, training_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n",
      "Completed 0\n",
      "Completed 100\n",
      "Completed 200\n",
      "Completed 300\n",
      "Completed 400\n",
      "Completed 500\n",
      "Completed 600\n",
      "Completed 700\n",
      "Completed 800\n",
      "Completed 900\n",
      "Completed 1000\n",
      "Completed 1100\n",
      "Completed 1200\n",
      "Completed 1300\n",
      "Completed 1400\n",
      "Completed 1500\n",
      "Completed 1600\n",
      "Completed 1700\n",
      "Completed 1800\n",
      "Completed 1900\n",
      "Completed 2000\n",
      "Completed 2100\n",
      "Completed 2200\n",
      "Completed 2300\n",
      "Completed 2400\n",
      "Completed 2500\n",
      "Completed 2600\n",
      "Completed 2700\n",
      "Completed 2800\n",
      "Completed 2900\n",
      "Completed 3000\n",
      "Completed 3100\n",
      "Completed 3200\n",
      "Completed 3300\n",
      "Completed 3400\n",
      "Completed 3500\n",
      "Completed 3600\n",
      "Completed 3700\n",
      "Completed 3800\n",
      "Completed 3900\n",
      "Completed 4000\n",
      "Completed 4100\n",
      "Completed 4200\n",
      "Completed 4300\n",
      "Completed 4400\n",
      "Completed 4500\n",
      "Completed 4600\n",
      "Completed 4700\n",
      "Completed 4800\n",
      "Completed 4900\n",
      "Completed 5000\n",
      "Completed 5100\n",
      "Completed 5200\n",
      "Completed 5300\n",
      "Completed 5400\n",
      "Completed 5500\n"
     ]
    }
   ],
   "source": [
    "print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
    "for epoch in range(VAL_EPOCHS):\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three killed in two blasts in Bangladesh</td>\n",
       "      <td>summarize: At least 3 killed, 30 injured in bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Over 30 blasts at ordnance factory in MP</td>\n",
       "      <td>summarize: 30 blasts occur at ordnance factory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centre dismisses reports of larger Nagaland state</td>\n",
       "      <td>summarize: Govt dismisses reports of carving o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thousands protest Brexit in London</td>\n",
       "      <td>summarize: Thousands march in London to protes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wankhede Stadium reserved for underprivileged ...</td>\n",
       "      <td>summarize: Underprivileged kids to fill Wankhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>Hanumantha Rao wrote to HRD in 2014: Irani</td>\n",
       "      <td>summarize: Congress MP wrote to HRD ministry i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11017</th>\n",
       "      <td>SPG moves SC against ban on new diesel vehicles</td>\n",
       "      <td>summarize: SPG seeks exception in SC ban on di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11018</th>\n",
       "      <td>Sonu Nigam surprises passengers with impromptu...</td>\n",
       "      <td>summarize: Sonu Nigam sings for co-passengers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>TRAI slams FB for &amp;#39;majoritarian&amp;#39; poll ...</td>\n",
       "      <td>summarize: TRAI slams FB for &amp;#39;orchestrated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11020</th>\n",
       "      <td>Ghulam Ali to make acting debut with &amp;#39;Ghar...</td>\n",
       "      <td>summarize: Ghulam Ali set to make acting debut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11021 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Generated Text  \\\n",
       "0               Three killed in two blasts in Bangladesh   \n",
       "1               Over 30 blasts at ordnance factory in MP   \n",
       "2      Centre dismisses reports of larger Nagaland state   \n",
       "3                     Thousands protest Brexit in London   \n",
       "4      Wankhede Stadium reserved for underprivileged ...   \n",
       "...                                                  ...   \n",
       "11016         Hanumantha Rao wrote to HRD in 2014: Irani   \n",
       "11017    SPG moves SC against ban on new diesel vehicles   \n",
       "11018  Sonu Nigam surprises passengers with impromptu...   \n",
       "11019  TRAI slams FB for &#39;majoritarian&#39; poll ...   \n",
       "11020  Ghulam Ali to make acting debut with &#39;Ghar...   \n",
       "\n",
       "                                             Actual Text  \n",
       "0      summarize: At least 3 killed, 30 injured in bl...  \n",
       "1      summarize: 30 blasts occur at ordnance factory...  \n",
       "2      summarize: Govt dismisses reports of carving o...  \n",
       "3      summarize: Thousands march in London to protes...  \n",
       "4      summarize: Underprivileged kids to fill Wankhe...  \n",
       "...                                                  ...  \n",
       "11016  summarize: Congress MP wrote to HRD ministry i...  \n",
       "11017  summarize: SPG seeks exception in SC ban on di...  \n",
       "11018  summarize: Sonu Nigam sings for co-passengers ...  \n",
       "11019  summarize: TRAI slams FB for &#39;orchestrated...  \n",
       "11020  summarize: Ghulam Ali set to make acting debut...  \n",
       "\n",
       "[11021 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('models/t5-inshorts/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
