{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BlenderbotSmallTokenizer, BlenderbotSmallForConditionalGeneration, \\\n",
    "TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news-expand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Australian batsman Steve Smith reveals he near...</td>\n",
       "      <td>australia batsman steve smith has revealed tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>milind soman recently trekked to the highest p...</td>\n",
       "      <td>milind soman needs no introduction and nor doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>singer Aditya Narayan shared a picture of hims...</td>\n",
       "      <td>ahead of his wedding (reportedly on december 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rubina Dilaik will reveal one of the deepest s...</td>\n",
       "      <td>tv star rubina dilaik will reveal one of the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the couple, who got married exactly a month ag...</td>\n",
       "      <td>it is a happy day for kajal aggarwal and her h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            summary  \\\n",
       "0           0  Australian batsman Steve Smith reveals he near...   \n",
       "1           1  milind soman recently trekked to the highest p...   \n",
       "2           2  singer Aditya Narayan shared a picture of hims...   \n",
       "3           3  Rubina Dilaik will reveal one of the deepest s...   \n",
       "4           4  the couple, who got married exactly a month ag...   \n",
       "\n",
       "                                                text  \n",
       "0  australia batsman steve smith has revealed tha...  \n",
       "1  milind soman needs no introduction and nor doe...  \n",
       "2  ahead of his wedding (reportedly on december 1...  \n",
       "3  tv star rubina dilaik will reveal one of the d...  \n",
       "4  it is a happy day for kajal aggarwal and her h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CustomDataset class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.summary\n",
    "        self.ctext = self.data.text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length = self.source_len, padding = 'max_length',\\\n",
    "                                                  return_tensors = 'pt', truncation = True)\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length = self.summ_len, padding = 'max_length',\\\n",
    "                                                  return_tensors = 'pt', truncation = True)\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze().to(dtype = torch.long)\n",
    "        source_mask = source['attention_mask'].squeeze().to(dtype = torch.long)\n",
    "        target_ids = target['input_ids'].squeeze().to(dtype = torch.long)\n",
    "        \n",
    "        y_ids = target_ids[:-1].contiguous() # make y_ids contiguous \n",
    "        lm_labels = target_ids[1:].clone().detach() # make fast copy\n",
    "        lm_labels[target_ids[1:] == tokenizer.pad_token_id] = -100 # replace pad tokens\n",
    "\n",
    "        return {\n",
    "            'input_ids': source_ids, \n",
    "            'attention_mask': source_mask, \n",
    "            'decoder_input_ids': y_ids,\n",
    "            'labels': lm_labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (8104, 2)\n",
      "TRAIN Dataset: (6483, 2)\n",
      "TEST Dataset: (1621, 2)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 2 \n",
    "TRAIN_EPOCHS = 10      \n",
    "VAL_EPOCHS = 1 \n",
    "LEARNING_RATE = 1e-4    \n",
    "SEED = 42               \n",
    "MAX_LEN = 256\n",
    "SUMMARY_LEN = 64\n",
    "\n",
    "torch.manual_seed(SEED) \n",
    "np.random.seed(SEED) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "tokenizer = BlenderbotSmallTokenizer.from_pretrained(\"facebook/blenderbot_small-90M\")\n",
    "\n",
    "df = df[['text','summary']]\n",
    "df.summary = 'summarize: ' + df.summary \n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = df.sample(frac=train_size,random_state = SEED)\n",
    "val_dataset = df.drop(train_dataset.index).reset_index(drop = True)\n",
    "train_dataset = train_dataset.reset_index(drop = True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
    "val_set = CustomDataset(val_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': TRAIN_BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': VALID_BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "model = BlenderbotSmallForConditionalGeneration.from_pretrained(\"facebook/blenderbot_small-90M\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(output_dir=\"blenderbot_small-news\",\n",
    "                         seed=42,\n",
    "                         num_train_epochs=10,\n",
    "                         per_device_train_batch_size=8,  \n",
    "                         # max batch size without OOM exception, because of the large max token length\n",
    "                         per_device_eval_batch_size=8,\n",
    "                         logging_steps=2500,\n",
    "                         save_steps=0,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='8110' max='8110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8110/8110 17:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.418900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.373800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8110, training_loss=0.7783910579657878, metrics={'train_runtime': 1071.7234, 'train_samples_per_second': 7.567, 'total_flos': 10858520018903040, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    texts = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(loader, 0)):\n",
    "            y = data['decoder_input_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length = 100, \n",
    "                num_beams = 2,\n",
    "                repetition_penalty = 2.5, \n",
    "                length_penalty = 1.0, \n",
    "                early_stopping = True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                     for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                      for t in y]\n",
    "            text = [tokenizer.decode(i, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                      for i in ids]\n",
    "            if _%2500==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "            texts.extend(text)\n",
    "    return predictions, actuals, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"blenderbot_small-news/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "811it [08:34,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 514.6453123092651 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(VAL_EPOCHS):\n",
    "    predictions, actuals, text = validate(epoch, tokenizer, model, device, val_loader)\n",
    "    final_df = pd.DataFrame({'Generated Text': predictions,'Actual Text': actuals, 'Text': text})\n",
    "print(\"Validation took \" + str(time.time() - start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out Generated vs Actual Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marize: rubina dilaik will reveal one of the d...</td>\n",
       "      <td>summarize: rubina dilaik will reveal one of th...</td>\n",
       "      <td>tv star rubina dilaik will reveal one of the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marize: the couple got married exactly a month...</td>\n",
       "      <td>summarize: the couple, who got married exactly...</td>\n",
       "      <td>it is a happy day for kajal aggarwal and her h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marize: the actor often acknowledges his ef ex...</td>\n",
       "      <td>summarize: amitabh bachchan's latest post is a...</td>\n",
       "      <td>there is absolutely no denying the fact that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marize: the netflix series fabulous lives of b...</td>\n",
       "      <td>summarize: a twitter user addressed karan joha...</td>\n",
       "      <td>karan johar, who is quite used to be being tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marize: the actress, who costarred with late a...</td>\n",
       "      <td>summarize: ankita lokhande is all set to perfo...</td>\n",
       "      <td>tv star ankita lokhande, who is all set to per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>marize: one day later de telegraaf, a daily am...</td>\n",
       "      <td>summarize: but there are other positive uses o...</td>\n",
       "      <td>mobile picture power in your pocket how many t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>marize: a delta spokesperson confirmed on wedn...</td>\n",
       "      <td>summarize: a delta spokesperson confirmed on w...</td>\n",
       "      <td>us blogger fired by her airline a us airline a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>marize: the trick is being used to prevent the...</td>\n",
       "      <td>summarize: a windows virus called bofra is tur...</td>\n",
       "      <td>toxic web links help virus spread virus writer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>marize: the system is not available commercial...</td>\n",
       "      <td>summarize: the system is not available commerc...</td>\n",
       "      <td>mobile networks seek turbo boost thirdgenerati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>marize: mitchell kapor, chairman of the mozill...</td>\n",
       "      <td>summarize: in a panel discussion at a linux su...</td>\n",
       "      <td>open source leaders slam patents the war of wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1621 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Generated Text  \\\n",
       "0     marize: rubina dilaik will reveal one of the d...   \n",
       "1     marize: the couple got married exactly a month...   \n",
       "2     marize: the actor often acknowledges his ef ex...   \n",
       "3     marize: the netflix series fabulous lives of b...   \n",
       "4     marize: the actress, who costarred with late a...   \n",
       "...                                                 ...   \n",
       "1616  marize: one day later de telegraaf, a daily am...   \n",
       "1617  marize: a delta spokesperson confirmed on wedn...   \n",
       "1618  marize: the trick is being used to prevent the...   \n",
       "1619  marize: the system is not available commercial...   \n",
       "1620  marize: mitchell kapor, chairman of the mozill...   \n",
       "\n",
       "                                            Actual Text  \\\n",
       "0     summarize: rubina dilaik will reveal one of th...   \n",
       "1     summarize: the couple, who got married exactly...   \n",
       "2     summarize: amitabh bachchan's latest post is a...   \n",
       "3     summarize: a twitter user addressed karan joha...   \n",
       "4     summarize: ankita lokhande is all set to perfo...   \n",
       "...                                                 ...   \n",
       "1616  summarize: but there are other positive uses o...   \n",
       "1617  summarize: a delta spokesperson confirmed on w...   \n",
       "1618  summarize: a windows virus called bofra is tur...   \n",
       "1619  summarize: the system is not available commerc...   \n",
       "1620  summarize: in a panel discussion at a linux su...   \n",
       "\n",
       "                                                   Text  \n",
       "0     tv star rubina dilaik will reveal one of the d...  \n",
       "1     it is a happy day for kajal aggarwal and her h...  \n",
       "2     there is absolutely no denying the fact that a...  \n",
       "3     karan johar, who is quite used to be being tro...  \n",
       "4     tv star ankita lokhande, who is all set to per...  \n",
       "...                                                 ...  \n",
       "1616  mobile picture power in your pocket how many t...  \n",
       "1617  us blogger fired by her airline a us airline a...  \n",
       "1618  toxic web links help virus spread virus writer...  \n",
       "1619  mobile networks seek turbo boost thirdgenerati...  \n",
       "1620  open source leaders slam patents the war of wo...  \n",
       "\n",
       "[1621 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('predsvsactual.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model in tensorflow to upload to huggingface model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = transformers.TFT5ForConditionalGeneration.from_pretrained(\"t5-tt-trainer/\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save_pretrained(\"t5-tt-trainer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
